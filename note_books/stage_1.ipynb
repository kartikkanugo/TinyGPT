{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ada705f",
   "metadata": {},
   "source": [
    "# Stage 1\n",
    "\n",
    "## PART A - TinyGPT Environment Setup\n",
    "\n",
    "This notebook initializes the TinyGPT environment â€” importing core libraries,  \n",
    "checking GPU availability, and printing library versions for reproducibility.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af4109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import platform\n",
    "import torch\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def _env_summary():\n",
    "    \"\"\"Print Python, Torch, NumPy, and tiktoken version details.\"\"\"\n",
    "    print(\"ðŸ”§ Environment Summary\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Python version : {platform.python_version()}\")\n",
    "    print(f\"Platform       : {platform.system()} {platform.release()}\")\n",
    "    print()\n",
    "    print(f\"Torch version  : {torch.__version__}\")\n",
    "    print(f\"NumPy version  : {np.__version__}\")\n",
    "    print(f\"Tiktoken ver.  : {tiktoken.__version__}\")\n",
    "    if \"pandas\" in sys.modules:\n",
    "        print(f\"Pandas version : {pd.__version__}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "def _cuda_info():\n",
    "    \"\"\"Check if CUDA is available and show GPU details.\"\"\"\n",
    "    print(\"âš™ï¸  CUDA & GPU Information\")\n",
    "    print(\"-\" * 50)\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"âœ… CUDA available: {torch.version.cuda}\")\n",
    "        print(f\"ðŸ§  GPU name      : {torch.cuda.get_device_name(0)}\")\n",
    "        print(\n",
    "            f\"ðŸ’½ Total memory  : {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"âŒ CUDA not available â€” running on CPU\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "def _test_tokenizer(sample_text=\"Once upon a time in TinyGPT...\"):\n",
    "    \"\"\"Quick test for tiktoken tokenizer functionality.\"\"\"\n",
    "    print(\"ðŸ”¤ Tokenizer Test (tiktoken)\")\n",
    "    print(\"-\" * 50)\n",
    "    enc = tiktoken.get_encoding(\"gpt2\")\n",
    "    tokens = enc.encode(sample_text)\n",
    "    print(f\"Input text : {sample_text}\")\n",
    "    print(f\"Tokens     : {tokens}\")\n",
    "    print(f\"Decoded    : {enc.decode(tokens)}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# Main function\n",
    "def initialize_tinygpt_env():\n",
    "    \"\"\"Run all setup checks together.\"\"\"\n",
    "    _env_summary()\n",
    "    _cuda_info()\n",
    "    _test_tokenizer()\n",
    "    print(\"âœ… TinyGPT environment initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72bc642a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Environment Summary\n",
      "--------------------------------------------------\n",
      "Python version : 3.13.7\n",
      "Platform       : Windows 11\n",
      "\n",
      "Torch version  : 2.9.0+cu130\n",
      "NumPy version  : 2.3.3\n",
      "Tiktoken ver.  : 0.12.0\n",
      "Pandas version : 2.3.3\n",
      "--------------------------------------------------\n",
      "âš™ï¸  CUDA & GPU Information\n",
      "--------------------------------------------------\n",
      "âœ… CUDA available: 13.0\n",
      "ðŸ§  GPU name      : NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "ðŸ’½ Total memory  : 8.59 GB\n",
      "--------------------------------------------------\n",
      "ðŸ”¤ Tokenizer Test (tiktoken)\n",
      "--------------------------------------------------\n",
      "Input text : Once upon a time in TinyGPT...\n",
      "Tokens     : [7454, 2402, 257, 640, 287, 20443, 38, 11571, 986]\n",
      "Decoded    : Once upon a time in TinyGPT...\n",
      "--------------------------------------------------\n",
      "âœ… TinyGPT environment initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "initialize_tinygpt_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91a19e6",
   "metadata": {},
   "source": [
    "## Part B â€“ Load TinyGPT Data\n",
    "\n",
    "- In this section, we load a large text dataset that will serve as the source for our tokens.\n",
    "- The verdict.txt is recommended by the reference book for initial experiments.\n",
    "- Later, we can extend or replace this dataset with any other dataset from Hugging Face, depending on our needs.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6d365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_file(file_path=\"../The_Verdict.txt\") -> str:\n",
    "    \"\"\"\n",
    "    Load a text file and return its content as a string.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the text file.\n",
    "\n",
    "    Returns:\n",
    "        str: Raw text content of the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            raw_text = f.read()\n",
    "        print(f\"Loaded '{file_path}' successfully!\")\n",
    "        print(f\"Total number of characters: {len(raw_text)}\")\n",
    "        print(f\"Preview (first 100 chars):\\n{raw_text[:100]}\")\n",
    "        return raw_text\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cce794f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded '../The_Verdict.txt' successfully!\n",
      "Total number of characters: 20479\n",
      "Preview (first 100 chars):\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g\n"
     ]
    }
   ],
   "source": [
    "raw_text = load_text_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
